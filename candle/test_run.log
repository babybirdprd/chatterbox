   Compiling candle v0.1.0 (D:\chatterbox-rs\candle)
warning: unused variable: `mel_40`
   --> src\chatterbox.rs:303:13
    |
303 |         let mel_40 = audio::compute_mel_spectrogram(
    |             ^^^^^^ help: if this is intentional, prefix it with an underscore: `_mel_40`
    |
    = note: `#[warn(unused_variables)]` (part of `#[warn(unused)]`) on by default

warning: `candle` (lib) generated 1 warning
    Finished `release` profile [optimized] target(s) in 35.24s
     Running `target\release\chatterbox.exe --text Hello --ref-audio reference.wav --output test_output.wav --device cpu`
Using CPU device...
Loading Chatterbox Turbo model...
[HiFTGenerator::new] START loading from mel2wav
[HiFTGenerator::new] in_ch=80, base_ch=512, n_fft=16
[HiFTGenerator::new] f0_predictor loaded
[HiFTGenerator::new] source_downs.0 loaded (ch=256, k=30, u=15)
[HiFTGenerator::new] source_resblocks.0 loaded
[HiFTGenerator::new] source_downs.1 loaded (ch=128, k=6, u=3)
[HiFTGenerator::new] source_resblocks.1 loaded
[HiFTGenerator::new] source_downs.2 loaded (ch=64, k=1, u=1)
[HiFTGenerator::new] source_resblocks.2 loaded
[S3Gen] HiFTGenerator (mel2wav) loaded successfully
Model loaded successfully.
[generate_speech] Loading reference audio...
Generating speech for: "Hello"
Reference audio: reference.wav
[generate_speech] ref_samples_orig len: 227809, sr: 24000
[generate_speech] Computing mel spectrograms...
[generate_speech] mel_40 (16k): [1, 40, 951]
[generate_speech] mel_80 (16k): [1, 80, 951]
[generate_speech] mel_80 (24k): [1, 80, 949]
[VoiceEncoder] input mels: b=1, t=951, m=40
[VoiceEncoder] LSTM layer 0: creating zeros (b=1, h=256)
[VoiceEncoder] LSTM layer 0: stacking 951 outputs
[VoiceEncoder] LSTM layer 0: hidden_states: [1, 951, 256]
[VoiceEncoder] LSTM layer 1: creating zeros (b=1, h=256)
[VoiceEncoder] LSTM layer 1: stacking 951 outputs
[VoiceEncoder] LSTM layer 1: hidden_states: [1, 951, 256]
[VoiceEncoder] LSTM layer 2: creating zeros (b=1, h=256)
[VoiceEncoder] LSTM layer 2: stacking 951 outputs
[VoiceEncoder] LSTM layer 2: hidden_states: [1, 951, 256]
[generate_speech] spk_emb_256: [1, 256]
[generate_speech] Running CAMPPlus...
[generate_speech] spk_emb_80: [1, 80]
[generate_speech] Running S3Tokenizer...
[generate_speech] prompt_tokens: [1, 238]
[generate_speech] text_tokens: [1, 5]
[generate_speech] Running T3.generate...
[T3] Generating token 0/500...
[T3] Generating token 10/500...
[T3] Generating token 20/500...
[T3] Generating token 30/500...
[T3] Generating token 40/500...
[T3] Generating token 50/500...
[generate_speech] speech_tokens: [1, 53]
[generate_speech] filtered tokens: 51 (from 53)
[generate_speech] Running S3Gen.forward...
[S3Gen::forward] speech_tokens: [1, 51]
[S3Gen::forward] embeds: [1, 51, 512]
[S3Gen::forward] encoder_out: [1, 102, 512]
[S3Gen::forward] mu (mel): [1, 80, 102]
[S3Gen::forward] cond tensor: [1, 80, 102]
[S3Gen::forward] mel after decoder: [1, 80, 102]
[S3Gen::forward] mel mean abs: 6.6513047
[HiFTGenerator::inference] mel input: [1, 80, 102]
[HiFTGenerator::inference] f0 range: [0.0010338873, 0.6070273]
[HiFTGenerator::inference] upsample_factor: 240
[generate_speech] audio_tensor: [1, 1, 24496]
Audio saved to: test_output.wav (24496 samples @ 24000Hz)
